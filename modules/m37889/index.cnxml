<document xmlns="http://cnx.rice.edu/cnxml">

<title>Reliability</title>
<metadata xmlns:md="http://cnx.rice.edu/mdml">
  <md:content-id>m37889</md:content-id>
  <md:title>Reliability</md:title>
  <md:abstract>A discussion of the importance of good reliability for assessment techniques.</md:abstract>
  <md:uuid>125a0661-52db-40b5-87a1-d639a5d75809</md:uuid>
</metadata>

<content>
    
      <note id="eip-912">The primary author of this module is Dr. Rosemary Sutton.</note><para id="id1164138525590">Reliability refers to the consistency of the measurement (Linn &amp; Miller 2005). Suppose Mr Garcia is teaching a unit on food chemistry in his tenth grade class and gives an assessment at the end of the unit using test items from the teachers’ guide. Reliability is related to questions such as: How similar would the scores of the students be if they had taken the assessment on a Friday or Monday? Would the scores have varied if Mr Garcia had selected different test items, or if a different teacher had graded the test? An assessment provides information about students by using a specific measure of performance at one particular time. Unless the results from the assessment are reasonably consistent over different occasions, different raters, or different tasks (in the same content domain) confidence in the results will be low and so cannot be useful in improving student learning. </para>
      <para id="id1164140915340">Obviously we cannot expect perfect consistency. Students’ memory, attention, fatigue, effort, and anxiety fluctuate and so influence performance. Even trained raters vary somewhat when grading assessment such as essays, a science project, or an oral presentation. Also, the wording and design of specific items influence students’ performances. However, some assessments are more reliable than others and there are several strategies teachers can use to increase reliability</para>
      <para id="id1164139074845">First, assessments with more tasks or items typically have higher reliability. To understand this, consider two tests one with five items and one with 50 items. Chance factors influence the shorter test more then the longer test. If a student does not understand one of the items in the first test the total score is very highly influenced (it would be reduced by 20 per cent). In contrast, if there was one item in the test with 50 items that were confusing, the total score would be influenced much less (by only 2 percent). Obviously this does not mean that assessments should be inordinately long, but, on average, enough tasks should be included to reduce the influence of chance variations. Second, clear directions and tasks help increase reliability. If the directions or wording of specific tasks or items are unclear, then students have to guess what they mean undermining the accuracy of their results. Third, clear scoring criteria are crucial in ensuring high reliability (Linn &amp; Miller, 2005). Later in this chapter we describe strategies for developing scoring criteria for a variety of types of assessment. </para>
  
</content>

</document>